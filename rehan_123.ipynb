{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b147f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\anaconda3\\new folder\\new folder\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\lenovo\\anaconda3\\new folder\\new folder\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lenovo\\anaconda3\\new folder\\new folder\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lenovo\\anaconda3\\new folder\\new folder\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lenovo\\anaconda3\\new folder\\new folder\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a256c89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2858ce8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from  sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (Iris Dataset)\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data(80% Train ,20% Test)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 42)\n",
    "\n",
    "# Create SVM model( Using RBF kennel )\n",
    "model = SVC(kernel='rbf',C=1.0,gamma = 'scale')\n",
    "\n",
    "# Train the Model \n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"SVM Model Accuracy :\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6824ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d110851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (Iris Dataset)\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data (80% Train ,20% Test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create KNN model (k=5)\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the Model \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25873e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (Iris Dataset)\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data (80% Train ,20% Test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create KNN model (k=5)\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the Model \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c08e2a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Accuracy on Digits Dataset: 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1) Load dataset (Digits)\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data      # Each image is 8x8 pixels, flattened into 64 features\n",
    "y = digits.target    # Labels: digits 0–9\n",
    "\n",
    "# 2) Split data (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Create KNN model (k=5)\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 4) Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Model Accuracy on Digits Dataset:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6cb3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (Iris Dataset)\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data (80% Train ,20% Test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create KNN model (k=5)\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the Model \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8fc0461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Accuracy on Digits Dataset: 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1) Load dataset (Digits)\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data      # Each image is 8x8 pixels, flattened into 64 features\n",
    "y = digits.target    # Labels: digits 0–9\n",
    "\n",
    "# 2) Split data (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Create KNN model (k=5)\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 4) Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Model Accuracy on Digits Dataset:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70afebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (Iris Dataset)\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Decision Tree model\n",
    "model = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "\n",
    "# Train\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Decision Tree Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721e8548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy on Digits Dataset: 0.8388888888888889\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        36\n",
      "           1       0.76      0.78      0.77        36\n",
      "           2       0.88      0.86      0.87        35\n",
      "           3       0.86      0.86      0.86        37\n",
      "           4       0.87      0.92      0.89        36\n",
      "           5       0.84      0.86      0.85        37\n",
      "           6       0.74      0.89      0.81        36\n",
      "           7       0.88      0.81      0.84        36\n",
      "           8       0.78      0.71      0.75        35\n",
      "           9       0.81      0.81      0.81        36\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.84      0.84      0.84       360\n",
      "weighted avg       0.84      0.84      0.84       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) Load dataset (Digits)\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data      # Each image is 8x8 pixels, flattened into 64 features\n",
    "y = digits.target    # Labels: digits 0–9\n",
    "\n",
    "# 2) Split data (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Create Decision Tree model\n",
    "model = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "\n",
    "# 4) Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Decision Tree Accuracy on Digits Dataset:\", accuracy)\n",
    "\n",
    "# 7) Extra: Detailed report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "289979d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (Iris Dataset)\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21496efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy on Diabetes Dataset: 0.7640449438202247\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1) Load dataset (Diabetes)\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data       # Features (medical measurements)\n",
    "y = diabetes.target     # Target (disease progression value)\n",
    "\n",
    "# Convert regression target into classification (High = 1, Low = 0)\n",
    "# We'll classify based on whether the value is above or below the median\n",
    "import numpy as np\n",
    "y_class = np.where(y > np.median(y), 1, 0)\n",
    "\n",
    "# 2) Split data (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "# 3) Create Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 4) Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy on Diabetes Dataset:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e98623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy on Diabetes Dataset: 0.7640449438202247\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1) Load dataset (Diabetes)\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data       # Features (medical measurements)\n",
    "y = diabetes.target     # Target (disease progression value)\n",
    "\n",
    "# Convert regression target into classification (High = 1, Low = 0)\n",
    "# We'll classify based on whether the value is above or below the median\n",
    "import numpy as np\n",
    "y_class = np.where(y > np.median(y), 1, 0)\n",
    "\n",
    "# 2) Split data (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "# 3) Create Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 4) Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy on Diabetes Dataset:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b05627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy on Breast Cancer Dataset: 0.956140350877193\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.93      0.94        42\n",
      "      benign       0.96      0.97      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) Load dataset (Breast Cancer)\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = cancer.data        # Features (measurements of cell nuclei)\n",
    "y = cancer.target      # Target (0 = malignant, 1 = benign)\n",
    "\n",
    "# 2) Split data (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Create Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 4) Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy on Breast Cancer Dataset:\", accuracy)\n",
    "\n",
    "# 7) Extra: Detailed performance report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "871f1ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (Iris Dataset)\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Logistic Regression model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Train\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8cc561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (RBF) Precision: 1.0000\n",
      "KNN Precision: 1.0000\n",
      "Decision Tree Precision: 1.0000\n",
      "Random Forest Precision: 1.0000\n",
      "Naive Bayes Precision: 1.0000\n",
      "Logistic Regression Precision: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Load dataset (Iris Dataset)\n",
    "iris = datasets.load_iris()\n",
    "x, y = iris.data, iris.target\n",
    "\n",
    "# Split data (80% Train ,20% Test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# List of models to test\n",
    "models = {\n",
    "    \"SVM (RBF)\": SVC(kernel='rbf', C=1.0, gamma='scale'),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(criterion=\"entropy\", random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200)\n",
    "}\n",
    "\n",
    "# Train & evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    print(f\"{name} Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8167ba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (RBF) Accuracy: 1.0000\n",
      "KNN Accuracy: 1.0000\n",
      "Decision Tree Accuracy: 1.0000\n",
      "Random Forest Accuracy: 1.0000\n",
      "Naive Bayes Accuracy: 1.0000\n",
      "Logistic Regression Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (Iris Dataset)\n",
    "iris = datasets.load_iris()\n",
    "x, y = iris.data, iris.target\n",
    "\n",
    "# Split data (80% Train ,20% Test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# List of models\n",
    "models = {\n",
    "    \"SVM (RBF)\": SVC(kernel='rbf', C=1.0, gamma='scale'),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(criterion=\"entropy\", random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07546332",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# 1) Imports\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# (Optional) make results repeatable\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 2) Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data      # features: 4 numbers per flower (sepal/petal length/width)\n",
    "y = iris.target    # labels: 0, 1, 2  (Setosa, Versicolor, Virginica)\n",
    "\n",
    "# 3) Train/Test split  (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4) Scale features (fit on train, transform train & test)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)   # learn scaling using only training data\n",
    "X_test  = scaler.transform(X_test)        # apply the same scaling to test data\n",
    "\n",
    "# 5) Build a very simple neural network\n",
    "# Input size = 4 (the 4 features)\n",
    "# Hidden layer = 16 neurons with ReLU (good default)\n",
    "# Output layer = 3 neurons with softmax (one score per class)\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# 6) Compile the model\n",
    "# - 'adam' optimizer: standard choice that usually works well\n",
    "# - 'sparse_categorical_crossentropy': use this when y is integer labels (0/1/2)\n",
    "# - track 'accuracy' during training\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 7) Train (fit) the model\n",
    "# - epochs: how many passes over the training data (start with 50)\n",
    "# - batch_size: how many samples per gradient update\n",
    "# - validation_split: keep 10% of training data to monitor progress\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    validation_split=0.1,\n",
    "    verbose=0  # set to 1 if you want to see the training log\n",
    ")\n",
    "\n",
    "# 8) Make predictions on the test set\n",
    "# model.predict gives probabilities for each of the 3 classes\n",
    "y_proba = model.predict(X_test)\n",
    "y_pred = y_proba.argmax(axis=1)  # choose the class with the highest probability\n",
    "\n",
    "# 9) Evaluate accuracy (and an optional per-class report)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Simple Neural Network (SNN) Accuracy:\", acc)\n",
    "\n",
    "print(\"\\nPer-class precision/recall/f1:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11967750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Neural Network (SNN) Accuracy: 0.9333333333333333\n",
      "\n",
      "Per-class metrics:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       0.90      0.90      0.90        10\n",
      "   virginica       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\New folder\\New folder\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) Load dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 2) Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Scale features (important for neural nets)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# 4) Create a Simple Neural Network (1 hidden layer, 16 neurons, ReLU activation)\n",
    "model = MLPClassifier(hidden_layer_sizes=(16,), activation='relu',\n",
    "                      solver='adam', max_iter=500, random_state=42)\n",
    "\n",
    "# 5) Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 7) Evaluate accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Simple Neural Network (SNN) Accuracy:\", acc)\n",
    "\n",
    "# 8) Per-class precision/recall/f1\n",
    "print(\"\\nPer-class metrics:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d78035ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Dataset - Simple Neural Network (SNN) Accuracy: 1.0\n",
      "\n",
      "Per-class metrics:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00        12\n",
      "     class_1       1.00      1.00      1.00        14\n",
      "     class_2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) Load dataset (Wine)\n",
    "wine = datasets.load_wine()\n",
    "X = wine.data      # 13 chemical features of wine\n",
    "y = wine.target    # 3 classes of wine\n",
    "\n",
    "# 2) Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# 4) Create a Simple Neural Network\n",
    "# - 1 hidden layer with 32 neurons\n",
    "# - ReLU activation\n",
    "# - Adam optimizer\n",
    "model = MLPClassifier(hidden_layer_sizes=(32,), activation='relu',\n",
    "                      solver='adam', max_iter=1000, random_state=42)\n",
    "\n",
    "# 5) Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 7) Evaluate accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Wine Dataset - Simple Neural Network (SNN) Accuracy:\", acc)\n",
    "\n",
    "# 8) Classification report (precision/recall/f1 per class)\n",
    "print(\"\\nPer-class metrics:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=wine.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b7f35d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Dataset - Simple Neural Network (SNN) Accuracy: 1.0\n",
      "\n",
      "Per-class metrics:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00        12\n",
      "     class_1       1.00      1.00      1.00        14\n",
      "     class_2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) Load dataset (Wine)\n",
    "wine = datasets.load_wine()\n",
    "X = wine.data      # 13 chemical features of wine\n",
    "y = wine.target    # 3 classes of wine\n",
    "\n",
    "# 2) Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# 4) Create a Simple Neural Network\n",
    "# - 1 hidden layer with 32 neurons\n",
    "# - ReLU activation\n",
    "# - Adam optimizer\n",
    "model = MLPClassifier(hidden_layer_sizes=(32,), activation='relu',\n",
    "                      solver='adam', max_iter=1000, random_state=42)\n",
    "\n",
    "# 5) Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 7) Evaluate accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Wine Dataset - Simple Neural Network (SNN) Accuracy:\", acc)\n",
    "\n",
    "# 8) Classification report (precision/recall/f1 per class)\n",
    "print(\"\\nPer-class metrics:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=wine.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4d9e33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy (Digits Dataset): 0.9611111111111111\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        36\n",
      "           1       0.90      0.97      0.93        36\n",
      "           2       1.00      0.97      0.99        35\n",
      "           3       0.97      0.97      0.97        37\n",
      "           4       0.97      0.97      0.97        36\n",
      "           5       0.97      1.00      0.99        37\n",
      "           6       1.00      0.97      0.99        36\n",
      "           7       0.92      1.00      0.96        36\n",
      "           8       0.94      0.86      0.90        35\n",
      "           9       0.97      0.92      0.94        36\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) Load dataset (Digits)\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data     # 8x8 images flattened into 64 features\n",
    "y = digits.target   # labels: 0 to 9\n",
    "\n",
    "# 2) Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Create Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 4) Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy (Digits Dataset):\", accuracy)\n",
    "\n",
    "# 7) Detailed report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c794dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression on Diabetes Dataset\n",
      "Mean Squared Error: 2900.1936284934804\n",
      "R² Score: 0.4526027629719196\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1) Load dataset (Diabetes)\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data      # 10 medical features (age, BMI, blood pressure, etc.)\n",
    "y = diabetes.target    # target: disease progression (continuous value)\n",
    "\n",
    "# 2) Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3) Create Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# 4) Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Evaluate performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Linear Regression on Diabetes Dataset\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R² Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef0fdf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor on Diabetes Dataset\n",
      "Mean Squared Error: 2952.0105887640448\n",
      "R² Score: 0.4428225673999313\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1) Load dataset (Diabetes)\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data      # 10 features (age, BMI, blood pressure, etc.)\n",
    "y = diabetes.target    # target: disease progression (continuous)\n",
    "\n",
    "# 2) Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3) Create Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# 4) Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Evaluate performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Regressor on Diabetes Dataset\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R² Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e5247a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression (SVR) on Diabetes Dataset\n",
      "Mean Squared Error: 2607.5422901898387\n",
      "R² Score: 0.5078392590548375\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1) Load dataset (Diabetes - regression problem)\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data      # 10 features (age, BMI, blood pressure, etc.)\n",
    "y = diabetes.target    # continuous target (disease progression)\n",
    "\n",
    "# 2) Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3) Scale features (important for SVR)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 4) Create Support Vector Regression model\n",
    "model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "\n",
    "# 5) Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 7) Evaluate performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Support Vector Regression (SVR) on Diabetes Dataset\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R² Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8730eb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy (Breast Cancer Dataset): 0.956140350877193\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.93      0.94        42\n",
      "      benign       0.96      0.97      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) Load dataset (Breast Cancer)\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = cancer.data      # features (30 medical measurements)\n",
    "y = cancer.target    # labels (0 = malignant, 1 = benign)\n",
    "\n",
    "# 2) Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Create Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 4) Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy (Breast Cancer Dataset):\", accuracy)\n",
    "\n",
    "# 7) Detailed report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeeff61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy (Breast Cancer Dataset): 0.956140350877193\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.93      0.94        42\n",
      "      benign       0.96      0.97      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) Load dataset (Breast Cancer)\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = cancer.data      # features (30 medical measurements)\n",
    "y = cancer.target    # labels (0 = malignant, 1 = benign)\n",
    "\n",
    "# 2) Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Create Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 4) Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy (Breast Cancer Dataset):\", accuracy)\n",
    "\n",
    "# 7) Detailed report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35763e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy (Breast Cancer Dataset): 0.956140350877193\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.93      0.94        42\n",
      "      benign       0.96      0.97      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) Load dataset (Breast Cancer)\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = cancer.data      # features (30 medical measurements)\n",
    "y = cancer.target    # labels (0 = malignant, 1 = benign)\n",
    "\n",
    "# 2) Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Create Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 4) Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5) Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6) Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy (Breast Cancer Dataset):\", accuracy)\n",
    "\n",
    "# 7) Detailed report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c974d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
